{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: requests in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (2.32.3)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 12.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rooty\\uwec\\sacm\\deeplearning\\deeplearning\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch numpy matplotlib requests torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "\n",
    "- This challenge will test your knowledge of PyTorch tensors.\n",
    "<br/>\n",
    "1. Create a tensor of size 10x10 with all elements equal to 0.5.\n",
    "2. Create a tensor with shape (1, 3, 3) with three `3`s, three `2`s, and three `4`s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.tensor([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2\n",
    "\n",
    "This challenge will test how well you can apply the concepts of deep learning.\n",
    "<br/>\n",
    "1. You are given an input with shape (1, 3) and a model with one layer, with weights in the shape (3, 1). There is no bias.\n",
    "2. The model also has the sigmoid activation function which takes the output of the weights as its input (remember what it spits out?).\n",
    "3. Identity what values the weights should be if the goal of this model is to map inputs with bigger values on the left to 0, and inputs with bigger values on the right to 1.\n",
    "4. Example `[1, 0, 0]` -> 0, `[1, 1, 3]` -> 1\n",
    "\n",
    "NOTE: Applying to Deep Learning to solve this problem is silly but its a good exercise :)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m w1, w2, w3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m w \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mw1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m act \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msigmoid()\n",
      "\u001b[1;31mTypeError\u001b[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,3)\n",
    "\n",
    "w1, w2, w3 = None, None, None\n",
    "\n",
    "w = torch.tensor([w1, w2, w3], dtype=torch.float32)\n",
    "\n",
    "act = F.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print()\n",
    "\n",
    "print(f'output = {act(x @ w)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3\n",
    "\n",
    "- Run the following code.\n",
    "- Be able to describe (almost all) of what is going on.\n",
    "- Play around with the model, the optimizer, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.298089  [   64/60000]\n",
      "loss: 2.292016  [ 6464/60000]\n",
      "loss: 2.268456  [12864/60000]\n",
      "loss: 2.269043  [19264/60000]\n",
      "loss: 2.253275  [25664/60000]\n",
      "loss: 2.221361  [32064/60000]\n",
      "loss: 2.233205  [38464/60000]\n",
      "loss: 2.191187  [44864/60000]\n",
      "loss: 2.194559  [51264/60000]\n",
      "loss: 2.164777  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 38.6%, Avg loss: 2.159276 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.167047  [   64/60000]\n",
      "loss: 2.163869  [ 6464/60000]\n",
      "loss: 2.100232  [12864/60000]\n",
      "loss: 2.121493  [19264/60000]\n",
      "loss: 2.069453  [25664/60000]\n",
      "loss: 2.008163  [32064/60000]\n",
      "loss: 2.043052  [38464/60000]\n",
      "loss: 1.952209  [44864/60000]\n",
      "loss: 1.971410  [51264/60000]\n",
      "loss: 1.904873  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.0%, Avg loss: 1.896052 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.925823  [   64/60000]\n",
      "loss: 1.906212  [ 6464/60000]\n",
      "loss: 1.780241  [12864/60000]\n",
      "loss: 1.831648  [19264/60000]\n",
      "loss: 1.721286  [25664/60000]\n",
      "loss: 1.668470  [32064/60000]\n",
      "loss: 1.705376  [38464/60000]\n",
      "loss: 1.587550  [44864/60000]\n",
      "loss: 1.638342  [51264/60000]\n",
      "loss: 1.542226  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 57.3%, Avg loss: 1.543022 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.605131  [   64/60000]\n",
      "loss: 1.578966  [ 6464/60000]\n",
      "loss: 1.417452  [12864/60000]\n",
      "loss: 1.502677  [19264/60000]\n",
      "loss: 1.385333  [25664/60000]\n",
      "loss: 1.370908  [32064/60000]\n",
      "loss: 1.395038  [38464/60000]\n",
      "loss: 1.300432  [44864/60000]\n",
      "loss: 1.355747  [51264/60000]\n",
      "loss: 1.261282  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 62.6%, Avg loss: 1.275588 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.348006  [   64/60000]\n",
      "loss: 1.337176  [ 6464/60000]\n",
      "loss: 1.162098  [12864/60000]\n",
      "loss: 1.276351  [19264/60000]\n",
      "loss: 1.155056  [25664/60000]\n",
      "loss: 1.171123  [32064/60000]\n",
      "loss: 1.194031  [38464/60000]\n",
      "loss: 1.116768  [44864/60000]\n",
      "loss: 1.171896  [51264/60000]\n",
      "loss: 1.090948  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.103788 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
